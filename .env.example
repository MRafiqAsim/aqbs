# Server Configuration
HOST=0.0.0.0
PORT=8000
ENVIRONMENT=development

# MongoDB Configuration
MONGODB_URL=mongodb://localhost:27017
MONGODB_DB_NAME=qbank

# File Storage Paths
UPLOAD_DIR=./uploads
EXTRACTED_TEXT_DIR=./extracted_text
GENERATED_QUESTIONS_DIR=./generated_questions

# LLM Configuration
LLM_PROVIDER=mlx  # Options: mlx, ollama, openai
MODEL_NAME=mlx-community/Meta-Llama-3-8B-Instruct-4bit
MODEL_CACHE_DIR=./models

# MLX Specific
MLX_MAX_TOKENS=2048
MLX_TEMPERATURE=0.7

# OpenAI (if using openai provider)
# OPENAI_API_KEY=your_openai_api_key_here

# Ollama (if using ollama provider)
# OLLAMA_BASE_URL=http://localhost:11434

# Text Extraction
MAX_CHUNK_SIZE=2000
CHUNK_OVERLAP=200

# Question Generation
DEFAULT_QUESTIONS_PER_CHUNK=5
MIN_DIFFICULTY=easy
MAX_DIFFICULTY=hard

# CORS Settings
CORS_ORIGINS=http://localhost:3000,http://localhost:3001

# Vector DB (Chroma)
CHROMA_PERSIST_DIR=./chroma_db
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
